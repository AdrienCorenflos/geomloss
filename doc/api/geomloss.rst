Maths and algorithms
=====================

Soon!

Going further
---------------

A comprehensive reference on the algorithms implemented
here will be provided in my **PhD thesis** (~ November 2019) - from CUDA tricks
to theoretical results on Sinkhorn divergences and applications to medical data.
Until then, you may be interested by:

  - My `slides <https://www.math.ens.fr/~feydy/Talks/GTTI_2019/GTTI_2019.pdf>`_
    on Hausdorff distances, Kernel MMDs and Sinkhorn divergences.
  - The `tutorial on gradient flows <https://www.math.ens.fr/~feydy/Teaching/DataScience/gradient_flows.html>`_
    that I wrote for students at the math department of the ENS.
  - Our `AiStats2019 paper <https://arxiv.org/abs/1810.08278>`_, which proves
    the **positive-definiteness** and convexity of Sinkhorn divergences.
  - Our `ShapeMI2018 paper <https://hal.archives-ouvertes.fr/hal-01827184/>`_, 
    which puts the three geometric loss functions
    in a **common framework**.
  - Bernhard Schmitzer's `sparse scaling paper <https://arxiv.org/abs/1610.06519>`_,
    which introduced the first **multiscale Sinkhorn loop**. 




